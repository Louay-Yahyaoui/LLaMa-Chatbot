{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":9273841,"datasetId":5499072,"databundleVersionId":9464998}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/loubl00m/llama-finetuned?scriptVersionId=194573016\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Loading modules","metadata":{}},{"cell_type":"code","source":"!pip install -U transformers peft bitsandbytes","metadata":{"_uuid":"110707a2-27ec-4e7f-b511-6577247a4aba","_cell_guid":"4d28621d-3bda-4dcd-804a-d7a7cf0b1707","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-29T14:42:21.186446Z","iopub.execute_input":"2024-08-29T14:42:21.186805Z","iopub.status.idle":"2024-08-29T14:42:51.012747Z","shell.execute_reply.started":"2024-08-29T14:42:21.186775Z","shell.execute_reply":"2024-08-29T14:42:51.01184Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nCollecting transformers\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes, transformers, peft\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\nSuccessfully installed bitsandbytes-0.43.3 peft-0.12.0 transformers-4.44.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n)\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nfrom datasets import load_dataset","metadata":{"_uuid":"5032a9e5-ca69-40f3-8260-64967ed07954","_cell_guid":"e8185547-215b-4643-837b-acf79c6a5225","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-29T14:42:51.014561Z","iopub.execute_input":"2024-08-29T14:42:51.014843Z","iopub.status.idle":"2024-08-29T14:42:56.366069Z","shell.execute_reply.started":"2024-08-29T14:42:51.014817Z","shell.execute_reply":"2024-08-29T14:42:56.365347Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf_token\")\nlogin(token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:42:56.367097Z","iopub.execute_input":"2024-08-29T14:42:56.367522Z","iopub.status.idle":"2024-08-29T14:42:56.95291Z","shell.execute_reply.started":"2024-08-29T14:42:56.367498Z","shell.execute_reply":"2024-08-29T14:42:56.95196Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading model from hugging face","metadata":{}},{"cell_type":"code","source":"torch_dtype = torch.float16\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Quantization config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type = \"nf4\",\n    bnb_4bit_compute_dtype = torch_dtype,\n    bnb_4bit_use_double_quant = True,\n)\n\n# Change it to load from hugging face.\nbase_path = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\nmodel_path = \"LouayYahyaoui/llama-edu\"\n\nbase_model = AutoModelForCausalLM.from_pretrained(base_path, quantization_config = bnb_config, \\\n                                                  device_map = device)\nmodel = PeftModel.from_pretrained(base_model, model_path)\ntokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"_uuid":"7d7b33e3-33f7-4e0e-8649-30e499845edf","_cell_guid":"5da35bcf-dd00-420d-9bbb-16b3c9997ca3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-29T14:42:56.954749Z","iopub.execute_input":"2024-08-29T14:42:56.955032Z","iopub.status.idle":"2024-08-29T14:44:40.356259Z","shell.execute_reply.started":"2024-08-29T14:42:56.955007Z","shell.execute_reply":"2024-08-29T14:44:40.355163Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a235cbbedca4c7da268ea73556567a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"769c709dfc504d09984b93998b061290"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ed177e0897482b8579dd54bd9cfb77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34fee13fd5c3445ea60bf3b445d7c98d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"458e50397b514830a07703cb1e6d9ffa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cd16b6c74714bf8abc3e4a750fdc89b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef58750d917c4b6c9fe2d9adaedfc8de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1974dbc07b0044db91e25afc6c413cfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c02e9dec66481a97adc57e247fd6ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/740 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b005170c43ef47cca6aa719627729198"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef86dc785ffc4c8b8791a97ccaff4066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81c1ee7a89442b6b2c3f3c9368fb927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595fe05950434c25a034d229496ecdfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/439 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff2b6993d82a458cbb15434f0c561dc1"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Interacting with the model","metadata":{}},{"cell_type":"code","source":"def answer(prompt):\n    if isinstance(prompt, str):\n        prompt = [{'role': 'system',\n        'content': 'You are an educational assistant that helps university students.'},\n         {'role': 'user',\n        'content': prompt}]\n    elif isinstance(prompt, list):\n        prompt = prompt[:2]\n    elif isinstance(prompt, dict):\n        prompt = prompt[\"messages\"][:2]\n    \n    end_header = \"<|end_header_id|>\"\n        \n    input_ids = tokenizer.apply_chat_template(prompt, tokenize = True, \\\n                                add_generation_prompt = True, return_tensors=\"pt\")\n    \n    \n    attention_mask = torch.ones_like(input_ids)\n    pad_token_id = tokenizer.pad_token_id \n\n    input_ids = input_ids.to(device)\n    out = model.generate(input_ids, max_new_tokens = 2048, do_sample = True, temperature = 0.6, \\\n    attention_mask = attention_mask, pad_token_id = pad_token_id) # just to shut down warnings.\n    \n    response = tokenizer.decode(out[0, input_ids.shape[-1]:], skip_special_tokens=True).strip()\n    \n    return response","metadata":{"_uuid":"68787a57-5c08-4647-bf89-a9405c026da1","_cell_guid":"d3a53861-f3b9-4748-81bf-2a3bd23a94be","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-29T14:44:40.357656Z","iopub.execute_input":"2024-08-29T14:44:40.357971Z","iopub.status.idle":"2024-08-29T14:44:40.368043Z","shell.execute_reply.started":"2024-08-29T14:44:40.357944Z","shell.execute_reply":"2024-08-29T14:44:40.366771Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Change prompt here\nprompt = \"I've been fine-tuning a model to improve its advice-giving and summarization capabilities. Could you suggest some best practices or strategies for further enhancing these skills in the model?\"\nprint(f\"User prompt: {prompt}\\n\\nAssistant: {answer(prompt)}\")","metadata":{"_uuid":"144c7ccb-9887-4aa2-88af-583663987a9b","_cell_guid":"a4363766-34a9-4a23-b563-e9a5733dc229","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-29T14:44:40.369572Z","iopub.execute_input":"2024-08-29T14:44:40.369847Z","iopub.status.idle":"2024-08-29T14:45:02.466695Z","shell.execute_reply.started":"2024-08-29T14:44:40.369823Z","shell.execute_reply":"2024-08-29T14:45:02.465695Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-08-29 14:44:43.334255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-29 14:44:43.334351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-29 14:44:43.450947: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"User prompt: I've been fine-tuning a model to improve its advice-giving and summarization capabilities. Could you suggest some best practices or strategies for further enhancing these skills in the model?\n\nAssistant: You can enhance the model's advice-giving and summarization capabilities by incorporating more diverse training data, fine-tuning on specific domains, and integrating with other AI tools for multimodal processing. Additionally, experimenting with different architectures and techniques such as attention mechanisms and transfer learning can also improve performance. Lastly, testing the model on various tasks and scenarios can provide valuable insights for further refinement.\n","output_type":"stream"}]}]}
